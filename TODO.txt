TODO:

TODO (maybe):

-explore covariance (or other metrics) between observed and expected rewards to see if the network is learning this (even when network.certainty ~= 0)
-maybe implement "autosaving" on some interval to avoid multiprocessing getting stuck
-consider programming in a resignation threshold to speed up training
-add estimated time remaining when training/generating data
-More visualizations to better understand network progress:
	-Euclidean distance of current weight vector relative to initial vector
	-Save some diverse set of examples, and graph activation sparsity on the set by layer
	-Top N lowest and N highest cost examples from a large data set (graph expected vs. recevied rewards)
	-take a snapshot of the weight vector at some time, find the top 2 PCs/ eigenvectors (?), and graph a time
	 series of points where the 2 axes of the graph are the PCs (each point is another snapshot of the weights)
-Consider recording 'certainty' on some interval so it can be graphed vs. number of training steps or unique examples
-add computational time as Network attribute (to supplement 'age' and 'experience')

Misc thoughts/worries:

-there are two functions for showing the current game for a Network, and the current one is a network_helper function when it should be a Network method probably

Eventually:

-allow the network freedom to parameterize its own training: namely at least having it compute some metric rating its competency, and weight the relative values of material to wins/losses accordingly.
