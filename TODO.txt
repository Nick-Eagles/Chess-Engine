TODO:

-allow choice of common optimizers via the config

TODO (maybe):

-explore covariance (or other metrics) between observed and expected rewards to see if the network is learning this (even when network.certainty ~= 0)
-consider programming in a resignation threshold to speed up training
-add estimated time remaining when training/generating data
-More visualizations to better understand network progress:
	-Euclidean distance of current weight vector relative to initial vector
	-Save some diverse set of examples, and graph activation sparsity on the set by layer
	-Top N lowest and N highest cost examples from a large data set (graph expected vs. recevied rewards)
	-take a snapshot of the weight vector at some time, find the top 2 PCs/ eigenvectors (?), and graph a time
	 series of points where the 2 axes of the graph are the PCs (each point is another snapshot of the weights)
-Consider recording 'certainty' on some interval so it can be graphed vs. number of training steps or unique examples
-add computational time as Network attribute (to supplement 'age' and 'experience')

Misc thoughts/worries:

-while the architecture related to the policy output is efficient in terms of using a low number of learnable parameters, information about the true probability distribution over legal moves is lossily compressed in a way which may be problematic, especially in particular positions. In reality, certain start sqaures are associated only with particular end squares and particular end pieces. However, these associations are totally lost (they are computed independently) with the current architecture

Verification:

-verify that choice of hyperparameters (excluding network arhcitecture) is reasonable to minimize loss on tf-starter datasets
-sample tf-starter datasets randomly and observe by eye that examples look reasonable
-(overall approach and program integrity) verify that a network can learn from an external chess dataset
-buffer.combine has no unit test

Eventually:

-allow the network freedom to parameterize its own training: namely at least having it compute some metric rating its competency, and weight the relative values of material to wins/losses accordingly.
